{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_726992/5419734.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import numpy as np \n",
    "import statsmodels.api as sm \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I - Pre-analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Before proceeding to MRI analyses, we must conduct a pre-analysis of test subjects : indeed their score in each category will be computed with machine learning algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Preliminary data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  participant_id  screen_bmi handedness             screen_race  \\\n",
      "0       sub-1001   22.128772       Left       Two or more races   \n",
      "1       sub-1002   21.284602      Right                   White   \n",
      "2       sub-1003   31.882086      Right  Black/African American   \n",
      "3       sub-1004   22.312012      Right       Two or more races   \n",
      "4       sub-1006   19.156142      Right                   White   \n",
      "\n",
      "  appt1_drugtest  appt1_breathalyzer        age    sex  deception  \\\n",
      "0       negative                 0.0  19.294145  Woman         10   \n",
      "1       negative                 0.0  21.139380    Man          6   \n",
      "2       negative                 0.0  18.992861  Woman          5   \n",
      "3       negative                 0.0  19.006550  Woman          3   \n",
      "4       negative                 0.0  20.654885    Man          1   \n",
      "\n",
      "   screen_meds_pastmonth  ...  audit_2  audit_3  audit_4  audit_5  audit_6  \\\n",
      "0                    1.0  ...      1.0      0.0      1.0      1.0      0.0   \n",
      "1                    0.0  ...      0.0      0.0      0.0      0.0      0.0   \n",
      "2                    0.0  ...      1.0      1.0      0.0      0.0      0.0   \n",
      "3                    0.0  ...      1.0      1.0      0.0      0.0      0.0   \n",
      "4                    NaN  ...      0.0      0.0      0.0      0.0      0.0   \n",
      "\n",
      "   audit_7  audit_8  audit_9  audit_10  ios_f  \n",
      "0      1.0      1.0      0.0       0.0    5.0  \n",
      "1      0.0      0.0      0.0       0.0    5.0  \n",
      "2      1.0      1.0      0.0       0.0    4.0  \n",
      "3      0.0      0.0      0.0       0.0    3.0  \n",
      "4      0.0      0.0      0.0       0.0    4.0  \n",
      "\n",
      "[5 rows x 437 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load phenotype data associated with participants\n",
    "phenotype_path = '/home/skander/ds004920/phenotype/'\n",
    "\n",
    "# List all files in the phenotype directory\n",
    "files = os.listdir(phenotype_path)\n",
    "\n",
    "# Initialize an empty DataFrame to accumulate phenotype data\n",
    "all_phenotype_data = pd.DataFrame()\n",
    "\n",
    "# Process each file\n",
    "for file in files:\n",
    "    file_path = os.path.join(phenotype_path, file)\n",
    "\n",
    "    if file.endswith('.tsv'):\n",
    "        # Load TSV file, considering multiple formats as NaN\n",
    "        temp_df = pd.read_csv(file_path, sep='\\t', na_values=['n/a', 'NA', 'na', 'N/A', ''])\n",
    "        # Append the data from each TSV file to the accumulated DataFrame\n",
    "        all_phenotype_data = pd.concat([all_phenotype_data, temp_df], ignore_index=True)\n",
    "\n",
    "# Aggregate the values for each phenotype\n",
    "aggregated_phenotype_data = all_phenotype_data.groupby('participant_id').sum().reset_index()\n",
    "\n",
    "# Load participants data\n",
    "participants_path = '/home/skander/ds004920/participants.tsv'\n",
    "participants_df = pd.read_csv(participants_path, sep='\\t', na_values=['n/a', 'NA', 'na', 'N/A', ''])\n",
    "\n",
    "# Merge aggregated phenotype data with participants data\n",
    "combined_df = pd.merge(participants_df, aggregated_phenotype_data, on='participant_id', how='left')\n",
    "\n",
    "# Display the first few rows of the combined DataFrame\n",
    "print(combined_df.head())\n",
    "\n",
    "# Define the file path for the CSV file in your /home directory\n",
    "#csv_file_path = '/home/skander/combined1.csv'\n",
    "\n",
    "# Save the combined DataFrame as a CSV file\n",
    "#combined_df.to_csv(csv_file_path, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We make it simpler by making an overall score, indeed 437 columns cannot give any information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  participant_id  screen_bmi handedness             screen_race  \\\n",
      "0       sub-1001        22.0       Left       Two or more races   \n",
      "1       sub-1002        21.0      Right                   White   \n",
      "2       sub-1003        31.0      Right  Black/African American   \n",
      "3       sub-1004        22.0      Right       Two or more races   \n",
      "4       sub-1006        19.0      Right                   White   \n",
      "\n",
      "  appt1_drugtest  appt1_breathalyzer   age    sex  deception  \\\n",
      "0       negative                 0.0  19.0  Woman         10   \n",
      "1       negative                 0.0  21.0    Man          6   \n",
      "2       negative                 0.0  18.0  Woman          5   \n",
      "3       negative                 0.0  19.0  Woman          3   \n",
      "4       negative                 0.0  20.0    Man          1   \n",
      "\n",
      "   screen_meds_pastmonth  ...  Interpersonal_Reactivity_Index  \\\n",
      "0                    1.0  ...                            66.0   \n",
      "1                    0.0  ...                            56.0   \n",
      "2                    0.0  ...                            57.0   \n",
      "3                    0.0  ...                            52.0   \n",
      "4                    0.0  ...                            69.0   \n",
      "\n",
      "   Social_reactivity  Positivity  Unpredictability_in_Childhood  Self_esteem  \\\n",
      "0               24.0         0.0                           13.0         22.0   \n",
      "1               21.0         0.0                            0.0         23.0   \n",
      "2               29.0         0.0                           19.0         24.0   \n",
      "3               12.0         0.0                           17.0         25.0   \n",
      "4               22.0         0.0                           15.0         25.0   \n",
      "\n",
      "   Sensitivity_to_punishment_reward  7_up_7_down  Social_Experience  \\\n",
      "0                              28.0         25.0               35.0   \n",
      "1                              36.0          2.0                0.0   \n",
      "2                              23.0          3.0               35.0   \n",
      "3                              19.0          0.0               31.0   \n",
      "4                              27.0          1.0               29.0   \n",
      "\n",
      "   Temporal_pleasure  Emotional_intelligence  \n",
      "0               89.0                   117.0  \n",
      "1               85.0                   125.0  \n",
      "2               82.0                    95.0  \n",
      "3               93.0                   119.0  \n",
      "4               68.0                   135.0  \n",
      "\n",
      "[5 rows x 39 columns]\n",
      "['participant_id', 'screen_bmi', 'handedness', 'screen_race', 'appt1_drugtest', 'appt1_breathalyzer', 'age', 'sex', 'deception', 'screen_meds_pastmonth', 'screen_meds_stabilizer', 'screen_meds_ssri', 'screen_meds_epilepsy', 'screen_meds_psychosis', 'screen_meds_antianxiety', 'screen_meds_pain', 'ios_f', 'juvenile_drug_alcohol_use', 'Alcohol_use', 'Mania_Scale', 'Autism_Quotient', 'Back_depression_inventory', 'Inhibited', 'Aggressive', 'Childhood_trauma', 'Drug_Use', 'PC_use', 'Friend_behavior', 'Stranger_behavior', 'Interpersonal_Reactivity_Index', 'Social_reactivity', 'Positivity', 'Unpredictability_in_Childhood', 'Self_esteem', 'Sensitivity_to_punishment_reward', '7_up_7_down', 'Social_Experience', 'Temporal_pleasure', 'Emotional_intelligence']\n"
     ]
    }
   ],
   "source": [
    "# Replace NaN or N/A values with 0\n",
    "combined_df = combined_df.replace('N/A', 0).fillna(0)\n",
    "\n",
    "# Remove duplicates, keeping the first occurrence\n",
    "combined_df = combined_df.drop_duplicates(subset='participant_id', keep='first')\n",
    "\n",
    "# Truncate the decimal places in 'screen_BMI' and 'age' without rounding\n",
    "combined_df['screen_bmi'] = combined_df['screen_bmi'].apply(lambda x: np.floor(x))\n",
    "combined_df['age'] = combined_df['age'].apply(lambda x: np.floor(x))\n",
    "\n",
    "# Function to sum columns based on containing specific substrings\n",
    "def sum_columns(df, substrings):\n",
    "    for substring, new_col_name in substrings.items():\n",
    "        # Select columns that contain the specific substring\n",
    "        selected_columns = df.filter(like=substring).columns\n",
    "\n",
    "        # Sum these columns and create a new column\n",
    "        df[new_col_name] = df[selected_columns].sum(axis=1)\n",
    "\n",
    "        #drop the original columns\n",
    "        df.drop(selected_columns, axis=1, inplace=True)\n",
    "\n",
    "# Dictionary mapping substrings to new column names\n",
    "substrings_to_merge = {\n",
    "    'aadis': 'juvenile_drug_alcohol_use',\n",
    "    'audit': 'Alcohol_use',\n",
    "    'asrm': 'Mania_Scale',\n",
    "    'aq': 'Autism_Quotient',\n",
    "    'bdi': 'Back_depression_inventory',\n",
    "    'bisbas': 'Inhibited',\n",
    "    'bpaq': 'Aggressive',\n",
    "    'ctqsf_adult_c': 'Childhood_trauma',\n",
    "    'dudit': 'Drug_Use',\n",
    "    'ios_computer': 'PC_use',\n",
    "    'ios_p': 'Friend_behavior',\n",
    "    'ios_fu_score': 'Stranger_behavior',\n",
    "    'iri': 'Interpersonal_Reactivity_Index',\n",
    "    'pnr': 'Social_reactivity',\n",
    "    'pvss': 'Positivity',\n",
    "    'quic_adult_cj': 'Unpredictability_in_Childhood',\n",
    "    'rse': 'Self_esteem',\n",
    "    'spsrq': 'Sensitivity_to_punishment_reward',\n",
    "    'susd': '7_up_7_down',\n",
    "    'seq_adult_cj': 'Social_Experience',\n",
    "    'score_teps': 'Temporal_pleasure',\n",
    "    'tei': 'Emotional_intelligence'\n",
    "    # ... Add any additional mappings here\n",
    "}\n",
    "\n",
    "# Perform the column summing based on substrings\n",
    "sum_columns(combined_df, substrings_to_merge)\n",
    "\n",
    "# Display the DataFrame for verification\n",
    "print(combined_df.head())\n",
    "\n",
    "# Print all column names in the DataFrame\n",
    "print(combined_df.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we have one column per medication used, we transform it into 2 features : Number of medication, and medication type (tbd : one-hot encore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a new column for the total drug use\n",
    "drug_columns = [\n",
    "    'screen_meds_stabilizer', 'screen_meds_ssri', 'screen_meds_epilepsy', \n",
    "    'screen_meds_psychosis', 'screen_meds_antianxiety', 'screen_meds_pain'\n",
    "]\n",
    "combined_df['total_drug_use'] = combined_df[drug_columns].sum(axis=1)\n",
    "\n",
    "# Function to create a list of medication names, removing 'screen_meds_'\n",
    "def list_medications(row, column_names):\n",
    "    medications = [col.replace('screen_meds_', '') for col in column_names if row[col] != 0]\n",
    "    return ', '.join(medications) if medications else 'None'\n",
    "\n",
    "# Add a new column listing the modified medication names\n",
    "combined_df['medication_names'] = combined_df.apply(lambda row: list_medications(row, drug_columns), axis=1)\n",
    "\n",
    "# Columns to be removed\n",
    "columns_to_remove = [\n",
    "    'screen_meds_stabilizer', 'screen_meds_ssri', 'screen_meds_epilepsy', \n",
    "    'screen_meds_psychosis', 'screen_meds_antianxiety', 'screen_meds_pain'\n",
    "]\n",
    "\n",
    "# Removing the specified columns from combined_df\n",
    "combined_df = combined_df.drop(columns=columns_to_remove)\n",
    "\n",
    "# Display the DataFrame for verification\n",
    "#print(combined_df.head())\n",
    "\n",
    "# Display the DataFrame for verification with a selection of columns\n",
    "#print(combined_df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Preliminary feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A - We take values who would be interpreted wrongfully as \"better\" or \"lesser\" (an age of 40 would be higher ranked than the age 20, which makes no sense), so let's transform these features into ranges use to categorize relevant data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transforming individual BMI's into BMI's ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Define a function to categorize BMI based on the provided ranges\n",
    "def categorize_bmi(bmi):\n",
    "    if bmi < 18.5:\n",
    "        return 'Underweight'\n",
    "    elif 18.5 <= bmi <= 24.9:\n",
    "        return 'Healthy Weight'\n",
    "    elif 25 <= bmi <= 29.9:\n",
    "        return 'Overweight'\n",
    "    elif 30 <= bmi <= 34.9:\n",
    "        return 'Obese'\n",
    "    elif 35 <= bmi <= 39.9:\n",
    "        return 'Severely Obese'\n",
    "    else:  # Assuming that any BMI of 40 or above is Morbidly Obese\n",
    "        return 'Morbidly Obese'\n",
    "\n",
    "# Apply the function to the 'screen_bmi' column to create a new 'bmi_category' column\n",
    "combined_df['bmi_category'] = combined_df['screen_bmi'].apply(categorize_bmi)\n",
    "\n",
    "# drop the original 'screen_bmi' column we won't use\n",
    "combined_df.drop('screen_bmi', axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transforming age into age ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function to categorize age\n",
    "def categorize_age(age):\n",
    "    if age <= 12:\n",
    "        return 'Child'\n",
    "    elif age <= 17:\n",
    "        return 'Teen'\n",
    "    elif age <= 24:\n",
    "        return 'Young Adult'\n",
    "    elif age <= 34:\n",
    "        return 'Adult'\n",
    "    elif age <= 44:\n",
    "        return 'Mature Adult'\n",
    "    elif age <= 54:\n",
    "        return 'Middle Aged'\n",
    "    elif age <= 64:\n",
    "        return 'Senior'\n",
    "    else:\n",
    "        return 'Elderly'\n",
    "\n",
    "# Apply the function to the 'age' column\n",
    "combined_df['age_category'] = combined_df['age'].apply(categorize_age)\n",
    "\n",
    "# We drop the original 'age' column as we no longer need it\n",
    "combined_df.drop('age', axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "saving a csv file for tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the file path for the CSV file in your /home directory\n",
    "#csv_file_path = '/home/skander/combined2.csv'\n",
    "\n",
    "# Save the DataFrame as a CSV file\n",
    "#combined_df.to_csv(csv_file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check = ok, results intended, proceeding to the next step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B - Hot-encoding categorial variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### hot-encoding is chosen rather than ordinal encoding, there is no hierarchy between data (e.g health and overweight may be interpreted as such, but we cannot say an Obese is hierarchically higher than a healthy or underweight person, it's hierarchy-independant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of categorical columns\n",
    "categorical_columns = ['bmi_category', 'age_category', 'medication_names', 'sex', 'handedness', 'screen_race']\n",
    "\n",
    "# Apply one-hot encoding\n",
    "for column in categorical_columns:\n",
    "    dummies = pd.get_dummies(combined_df[column], prefix=column)\n",
    "    combined_df = pd.concat([combined_df, dummies], axis=1)\n",
    "    combined_df.drop(column, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C - Gaussian distribution : normalization vs standardization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Determining if we have a gaussian distribution, which is critical to make our model tailored for deep learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
